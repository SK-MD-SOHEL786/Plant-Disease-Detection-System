{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ffb0b2f-e6f9-4a48-9f2e-16ba51a81a6f",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e4e8e4d-685c-412a-a7a7-f6b2b7883f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95411e24-04cd-4cda-b27f-cd52a91f7506",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f93bf91-93ae-4f5c-ad75-9cd6428a8808",
   "metadata": {},
   "source": [
    "Training Image Processing  (keras imgae data loading all explanation mentioned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837e3e78-0895-4e6b-8f85-cc6dd55fae32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set= tf.keras.utils.image_dataset_from_directory(\n",
    "    'train',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e8e99c-2db1-4b39-8b6a-6ffdb21189a1",
   "metadata": {},
   "source": [
    "labels =\"inferred\"  ---> it means go to my directory and take the label name as what ever the class name is there\n",
    "labels =classes     label1=bacterial_spot  lebel2 ...\n",
    "class_names =\"none \"  ---->   label is already given so no class name reqired\n",
    "batch_size=32      ---> At a time 32 images are going to feed in the model\n",
    "image_size=128,128\n",
    "shuffle=True   ----> shuffle the classes at the time of training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5785455-ff32-4a61-b04a-8b825043c43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 963 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set= tf.keras.utils.image_dataset_from_directory(\n",
    "    'val',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbec29b-bf6c-468d-8284-7898974b4f10",
   "metadata": {},
   "source": [
    "##training_set --> run it and we will get the full info about the training set  \n",
    "o/p--> <BatchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None)\n",
    "                                   , TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>\n",
    "128,128 -->image size ,3-->RGB format,   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee0457c-c16d-469f-880c-52fa5364333a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b215df61-c43c-4f20-a00c-b460cc8487a5",
   "metadata": {},
   "source": [
    "BUILDING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76d95b94-a468-4a18-b328-3de99ddba574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D,Dense,MaxPool2D,Flatten,Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c971b75-3565-4db0-b344-bc4e263cf5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a63963-57c4-4ddb-9353-91c66d8722e3",
   "metadata": {},
   "source": [
    "BUILDING CONVOLUTIONAL LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd1bed92-847a-4f57-b2ff-b78627522966",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',input_shape=[128,128,3]))\n",
    "model.add(Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05d1c896-1f7e-46f7-b7c8-f589b5e095f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e2d0cca-19db-4dee-ac22-25fed456948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=128,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(Conv2D(filters=128,kernel_size=3,activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea0a92fd-4925-4f6e-84ce-b2142bf422bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=256,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(Conv2D(filters=256,kernel_size=3,activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6d00080-3c0d-4eda-aeb4-d2ba163c9b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=512,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(Conv2D(filters=512,kernel_size=3,activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dc2f061-c617-4be6-902e-312a2cd3cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1babfe6b-6348-42e8-93e0-48a89f2acca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a132b80-1c2c-4b8c-b81e-cd42c9bc4eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1024,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aee12b86-ed91-424c-aee8-daca01c7e874",
   "metadata": {},
   "outputs": [],
   "source": [
    "##output layer\n",
    "model.add(Dense(units=10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fffa771-f1c7-40c6-be48-e8a589adb8ec",
   "metadata": {},
   "source": [
    "COMPILING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1477e2b4-96a6-441d-89d6-c5c5ae95335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08804a6c-7fdd-4ff6-941f-9cad6058272d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 126, 126, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 63, 63, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 61, 61, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 30, 30, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,820,650\n",
      "Trainable params: 6,820,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de3179b-1e2a-46fd-9541-96b6ef822e04",
   "metadata": {},
   "source": [
    "MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98055a55-3eb6-4921-95f4-cf73e8c87701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 389s 1s/step - loss: 1.3986 - accuracy: 0.5032 - val_loss: 0.7628 - val_accuracy: 0.7352\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 365s 1s/step - loss: 0.6390 - accuracy: 0.7710 - val_loss: 0.9520 - val_accuracy: 0.6854\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 358s 1s/step - loss: 0.4424 - accuracy: 0.8445 - val_loss: 0.4472 - val_accuracy: 0.8546\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 363s 1s/step - loss: 0.3160 - accuracy: 0.8888 - val_loss: 0.4020 - val_accuracy: 0.8577\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 356s 1s/step - loss: 0.2549 - accuracy: 0.9116 - val_loss: 0.4809 - val_accuracy: 0.8463\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 630s 2s/step - loss: 0.1955 - accuracy: 0.9318 - val_loss: 0.3721 - val_accuracy: 0.8744\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 666s 2s/step - loss: 0.1570 - accuracy: 0.9441 - val_loss: 0.3734 - val_accuracy: 0.8785\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 666s 2s/step - loss: 0.1223 - accuracy: 0.9575 - val_loss: 0.3687 - val_accuracy: 0.8910\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 673s 2s/step - loss: 0.1100 - accuracy: 0.9620 - val_loss: 0.3662 - val_accuracy: 0.8806\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 680s 2s/step - loss: 0.0808 - accuracy: 0.9715 - val_loss: 0.5308 - val_accuracy: 0.8619\n"
     ]
    }
   ],
   "source": [
    "training_history=model.fit(x=training_set,validation_data=validation_set,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d420ef01-b445-4bf6-a394-fb022b6057e2",
   "metadata": {},
   "source": [
    "MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f930d57-6762-49b0-b149-6631e613d7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 99s 316ms/step - loss: 0.1509 - accuracy: 0.9452\n"
     ]
    }
   ],
   "source": [
    "train_loss,train_accuracy=model.evaluate(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a493aff2-5fd6-44c2-aa86-5a611edded9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1508948802947998 0.9452000260353088\n"
     ]
    }
   ],
   "source": [
    "print(train_loss,train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c99a0bae-8742-4738-9b27-6b7108e596b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 10s 306ms/step - loss: 0.5308 - accuracy: 0.8619\n"
     ]
    }
   ],
   "source": [
    "val_loss,val_accuracy=model.evaluate(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31a45c37-fc02-42ae-a228-2da949c65b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53084397315979 0.8618898987770081\n"
     ]
    }
   ],
   "source": [
    "print(val_loss,val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f29d317-48d2-4ba4-ae5e-7e24bced6c3a",
   "metadata": {},
   "source": [
    "SAVING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79438860-9e4e-48f2-969b-d0edf2756d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_Model.keras\")"
   ]
  }
 
